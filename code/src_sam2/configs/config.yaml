# =============================================================================
# SAM2-UNET - Scientific Image Forgery Detection
# =============================================================================
# Configuration pour le projet Master DSC - Kaggle Competition
# Detection et segmentation de regions falsifiees avec SAM2 Hiera + UNET
#
# SAM2 (Segment Anything Model 2) utilise le backbone Hiera qui produit
# des features hierarchiques multi-echelles, ideal pour la segmentation.

# -----------------------------------------------------------------------------
# Experiment Settings
# -----------------------------------------------------------------------------
experiment:
  name: "sam2_unet_forgery_detection"
  seed: 42
  work_dir: "./work_dir"
  device: "cuda"
  gpu_id: 0

# -----------------------------------------------------------------------------
# Data Settings
# -----------------------------------------------------------------------------
data:
  data_root: "../input"
  train_csv: "train.csv"
  val_csv: "val.csv"
  test_csv: "test.csv"
  train_images_dir: "train/images"
  train_masks_dir: "train/masks"
  val_images_dir: "val/images"
  val_masks_dir: "val/masks"
  test_images_dir: "test/images"
  test_masks_dir: "test/masks"
  # SAM2/Hiera: taille doit être divisible par 32 (stride du réseau)
  # Tailles recommandées: 512, 544, 576, 640, 768, 1024
  # Le code gère automatiquement le padding si nécessaire
  image_size: 512
  num_workers: 8
  pin_memory: true
  include_authentic: true
  max_images_per_class: null
  max_samples_train: null
  max_samples_val: null
  max_samples_test: null

# -----------------------------------------------------------------------------
# Model Settings - SAM2 Hiera + UNET
# -----------------------------------------------------------------------------
model:
  # Backbone SAM2 Hiera - versions disponibles:
  # - sam2_hiera_t (tiny, ~155MB, rapide)
  # - sam2_hiera_s (small, ~185MB)
  # - sam2_hiera_b+ (base plus, ~325MB, RECOMMANDÉ)
  # - sam2_hiera_l (large, ~900MB, meilleure qualité)
  #
  # Note: "sam2_hiera_b" est un alias pour "sam2_hiera_b+"
  backbone: "sam2_hiera_b+"
  
  # Chemin vers les poids SAM2 locaux (téléchargés avec download_weights.py)
  # Le checkpoint SAM2 complet contient encoder + decoder, on extrait l'encoder
  weights_path: "model/sam2_hiera_base_plus.pt"
  
  # Configuration du décodeur UNet
  # SAM2 neck produit 256 canaux pour toutes les échelles
  decoder_channels: [256, 128, 64, 32]
  num_groups: 8
  
  # Geler le backbone pendant X epochs
  freeze_backbone: true
  freeze_backbone_epochs: 5
  
  # Checkpoint pré-entraîné sur votre dataset (optionnel)
  pretrained_checkpoint: ""

# -----------------------------------------------------------------------------
# Loss Settings
# -----------------------------------------------------------------------------
loss:
  type: "combined"
  bce:
    enabled: true
    weight: 1.0
    use_ilw: true
    ilw_max_weight: 10.0
    ilw_min_weight: 0.1
  dice:
    enabled: true
    weight: 1.0
    smooth: 1.0
  focal:
    enabled: false
    weight: 1.0
    alpha: 0.25
    gamma: 2.0
  lambda_pred_score: 0.05
  ignore_label: -1

# -----------------------------------------------------------------------------
# Training Settings
# -----------------------------------------------------------------------------
training:
  num_epochs: 150
  # SAM2 est plus gourmand en mémoire que DINOv2, ajuster le batch_size
  # Pour hiera_b+ avec 512x512: batch_size 8-12 sur 24GB GPU
  # Pour hiera_b+ avec 1024x1024: batch_size 2-4 sur 24GB GPU
  batch_size: 16
  gradient_accumulation_steps: 1 # Effective batch = 16
  lr: 0.0003
  weight_decay: 0.01
  backbone_lr_multiplier: 0.1
  scheduler:
    type: "cosine_warm_restarts"
    T_0: 15
    T_mult: 2
    eta_min: 0.000001
  resume_checkpoint: ""
  val_every: 1
  use_amp: true
  use_ema: true
  ema_decay: 0.999
  grad_clip_norm: 1.0
  early_stopping:
    enabled: true
    patience: 25
    min_delta: 0.0001
    metric: "val_oF1"
    mode: "max"

# -----------------------------------------------------------------------------
# Data Augmentation Settings
# -----------------------------------------------------------------------------
augmentation:
  type: 0
  crop_prob: 0
  resize_mode: null

# -----------------------------------------------------------------------------
# Inference Settings
# -----------------------------------------------------------------------------
inference:
  threshold: 0.5
  min_area: 100

# -----------------------------------------------------------------------------
# Evaluation Settings (oF1 metric)
# -----------------------------------------------------------------------------
evaluation:
  compute_oF1: true
  oF1:
    threshold: 0.5
    min_area: 100

# -----------------------------------------------------------------------------
# Logging Settings
# -----------------------------------------------------------------------------
logging:
  tensorboard: true
  log_every: 10
  verbose: true

# -----------------------------------------------------------------------------
# Distributed Training (optionnel)
# -----------------------------------------------------------------------------
distributed:
  enabled: false
  backend: "nccl"
  bucket_cap_mb: 25
